{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Content Guide:\n",
    "\n",
    "Content References\n",
    "\n",
    "Courses:\n",
    "1. CS285 (Fall 2020): Deep Reinforcement Learning (UC Berkeley)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "2. 10-708 PGM (Spring 2020): Probabalistic Graphical Models (Carnegie Mellon University)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "3. CS118 (Full Recommended Lecture Set): Intro to AI (UC Berkeley)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "4. CS229 (Fall 2018): Introduction to Machine Learning (Stanford)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "5. CS231n (Spring 2017): Deep Learning for Computer Vision (Stanford)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "6. CS224n (Fall 2019): Natural Language Processing with Deep Learning (Stanford)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "7. 10-715 (Fall 2018): Advanced Introduction to Machine Learning (Carnegie Mellon University)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "8. 10-725 (Fall 2018): Convex Optimization (Carnegie Mellon University)\n",
    "    - [ ] Video Lectures:\n",
    "    - [ ] Lecture Notes:\n",
    "\n",
    "Reading Courses: \\\n",
    "9. Statistics: All of Statistics (Larry Wasserman), Statistical Inference (Casella and Berger) \\\n",
    "10. The Deep Learning Book \\\n",
    "11. Introduction to Algorithms (CLRS) \n",
    "\n",
    "Lecture Note \n",
    "Research Reading List:\n",
    "\n",
    "\n",
    "- [ ] Machine Learning:\n",
    "    - [ ] AI Fundamentals (CS188):\n",
    "        - [ ] Depth First Search and Breadth First Search (DFS and BFS; See Graph Algorithms)\n",
    "        - [ ] A* Search\n",
    "        - [ ] Alpha-Beta Pruning\n",
    "        - [ ] D-Separation\n",
    "        - [ ] Variable Elminimation (One or More Variables)\n",
    "        - [ ] Maximum Liklihood\n",
    "        - [ ] Laplace Smoothing and Perceptrons\n",
    "    - [ ] Generalized Linear Models\n",
    "        - [ ] Linear Regression:\n",
    "        - [ ] Logistic Regression:\n",
    "        - [ ] General Linear Model (Guassian ...):\n",
    "        - [ ] Multinomial Regression:\n",
    "        - [ ] Bayesian Methods:\n",
    "    - [ ] Guassian Mixture Models\n",
    "        - [ ] Expectation Maximization\n",
    "    - [ ] Markov Decision Processes\n",
    "    - [ ] Guassian Discriminant Analysis\n",
    "    - [ ] PCA\n",
    "    - [ ] ICA\n",
    "    - [ ] Factor Analysis\n",
    "    - [ ] Guassian Processes\n",
    "    - [ ] Boosted Decision Trees\n",
    "    - [ ] Random Forests\n",
    "    - [ ] Support Vector Machines\n",
    "        - [ ] Generic and Slack Criterion\n",
    "    - [ ] Kernel Methods\n",
    "        - [ ] Kernel Ridge Regression\n",
    "    - [ ] Unconstrained Optimization\n",
    "    - [ ] Techniques:\n",
    "        - [ ] Dimensionality Reduction\n",
    "        - [ ] Clustering\n",
    "        - [ ] Feature Selection\n",
    "            - [ ] Exploratory Data Analysis\n",
    "            - [ ] Data Preprocessing\n",
    "        - [ ] Feature Engineering\n",
    "        - [ ] Model Selection (Cross-Valudation, ...)\n",
    "        - [ ] Pragmatics (Practical Tips for Training, Validation, Implementation, Troubleshooting, and more)\n",
    "    - [ ] Ensemble Methods\n",
    "        - [ ] Boosting\n",
    "        - [ ] Bootstrap Aggregation (Bagging)\n",
    "    - [ ] Bias Vs. Variance\n",
    "    - [ ] Regularization\n",
    "    - [ ] Training Tips\n",
    "    - [ ] Statistical Learning Theory\n",
    "    - [ ] Bayesian Networks (Part 1)\n",
    "        - [ ] Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics Content Guide:\n",
    "- [ ] Probability\n",
    "    - [ ] Introductory Concepts\n",
    "    - [ ] Random Variables\n",
    "    - [ ] Expectation\n",
    "    - [ ] Inequalities\n",
    "    - [ ] Convergence of Random Variables\n",
    "    - [ ] Markov Models\n",
    "    - [ ] Hidden Markov Models\n",
    "    - [ ] Bayes Nets\n",
    "- [ ] Statistical Ingerence\n",
    "    - [ ] Models, Statistical Inference, and Learning\n",
    "    - [ ] Estimating the CDF and Statistical Fundamentals\n",
    "    - [ ] The Bootstrap\n",
    "    - [ ] Parametric Inference\n",
    "    - [ ] Hypothesis Testing and p-values\n",
    "    - [ ] Bayesian Inference\n",
    "    - [ ] Statistical Decision Theory\n",
    "- [ ] Statistical Models and Methods\n",
    "    - [ ] Linear and Logistic Regression\n",
    "    - [ ] Multivariate Models\n",
    "    - [ ] Infrence About Independence\n",
    "    - [ ] Causal Inference\n",
    "    - [ ] Directed Graphs\n",
    "    - [ ] Directed Graphs and Conditional Independence\n",
    "    - [ ] Undirected Graphs\n",
    "    - [ ] Log-Linear Models\n",
    "    - [ ] Nonparametric Curve Estimation\n",
    "    - [ ] Smoothing Using Orthodinal Functions\n",
    "    - [ ] Classification\n",
    "    - [ ] Probability Redux: Stocastic Processes\n",
    "    - [ ] Simulation Methods\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algorithms Content Guide:\n",
    "- [ ] Algorithms:\n",
    "    - [ ] Data Structures:\n",
    "        - [ ] Stack\n",
    "        - [ ] Queue\n",
    "        - [ ] Dequeue\n",
    "        - [ ] List\n",
    "        - [ ] Linked List\n",
    "        - [ ] Sets\n",
    "        - [ ] Heaps\n",
    "            - [ ] Binary Heaps\n",
    "        - [ ] Trees\n",
    "            - [ ] Binary Search Trees (BST)\n",
    "            - [ ] Red Black Trees\n",
    "            - [ ] B-Trees\n",
    "        - [ ] Graphs\n",
    "            - [ ] Graphs\n",
    "            - [ ] Depth First Search\n",
    "            - [ ] Breadth First Search\n",
    "            - [ ] Shortest Path\n",
    "                - [ ] Dijkstras\n",
    "                - [ ] Bellman-Ford\n",
    "                - [ ] Floyd-Walsh (All pairs shortest path)\n",
    "            - [ ] Minimum Spanning Trees (MST)\n",
    "              - [ ] Growing a Minimum Spanning Tree\n",
    "              - [ ] Kruskal and Prim\n",
    "    - [ ] Sorting:\n",
    "        - [ ] Insertion Sort\n",
    "        - [ ] Selection Sort\n",
    "        - [ ] Merge Sort\n",
    "        - [ ] Quick Sort\n",
    "        - [ ] Radix Sort\n",
    "        - [ ] Bubble Sort\n",
    "    - [ ] Searching:\n",
    "        - [ ] Binary Search\n",
    "    - [ ] Dynamic Programming:\n",
    "    - [ ] Linear Programming:\n",
    "        - [ ] Standard and Slack Forms\n",
    "        - [ ] Formulation as Linear Programs\n",
    "        - [ ] The Simplex Algorithm\n",
    "        - [ ] Duality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning Content Guide:\n",
    "- [ ] Deep Learning:\n",
    "    - [ ] Base Model Architectures:\n",
    "        - [ ] ANN (FC / DFC)\n",
    "        - [ ] CNN\n",
    "        - [ ] RNN\n",
    "        - [ ] LSTM\n",
    "        - [ ] GRU\n",
    "        - [ ] Transformer Network (TN)\n",
    "        - [ ] Autoencoder (AE)\n",
    "        - [ ] Variational Autoencoder (VAE)\n",
    "        - [ ] Generative Adverserial Network (GAN)\n",
    "        - [ ] Deep Residual Network (DRN)\n",
    "    - [ ] Fundamental Research Problems / Topics:\n",
    "        - [ ] Dimensionality Reduction\n",
    "        - [ ] Architecture Selection Problem\n",
    "        - [ ] Objective Function Specification (The Control Problem)\n",
    "        - [ ] Feature Selection Problem\n",
    "        - [ ] Model Selection Problem\n",
    "        - [ ] Exploration Exploitation Problem\n",
    "        - [ ] Optimization / Convergence Guarantees\n",
    "        - [ ] Underspecification Problem\n",
    "        - [ ] Adversarial Example Problem (Preimage Problem)\n",
    "        - [ ] Universal Representator Problem (Two Layer ANN is a Universal Representor)\n",
    "        - [ ] Meta-Learning / AutoML Problems (??)\n",
    "        - [ ] Reproducibility\n",
    "        - [ ] Systems Perspectives\n",
    "            - [ ] Sensitivity Analysis\n",
    "    - [ ] Illustrative Techniques, Training Methods, Concepts, Problems, etc.\n",
    "        - [ ] CNNs\n",
    "        - [ ] RNNs\n",
    "            - [ ] Vanilla RNNs\n",
    "            - [ ] LSTMs\n",
    "            - [ ] GRUs\n",
    "        - [ ] Transformers\n",
    "        - [ ] Vanishing / Exploding Gradient Problem(s)\n",
    "        - [ ] Weight Initialization Problem\n",
    "        - [ ] Weight Activation Selection Problem\n",
    "        - [ ]        \n",
    "\n",
    "    - [ ] Illustrative Tasks Categories\n",
    "        - [ ] Computer Vision\n",
    "            - [ ] Object Classification\n",
    "            - [ ] Object Detection\n",
    "            - [ ] Object Segmentation\n",
    "            - [ ] Instance Detection\n",
    "            - [ ] Instance Segmentation\n",
    "            - [ ] Captioning\n",
    "            - [ ] Hybrid Tasks: Dense Captioning ('Instance Captioning'), Image Question Answering, etc.\n",
    "            - [ ] Embeddings\n",
    "            - [ ] Visualization\n",
    "            - [ ] Image Generation\n",
    "        - [ ] Computer Vision\n",
    "            - [ ] Text Classification\n",
    "                - [ ] Sentiment Analysis, Spam Filtering, ...\n",
    "            - [ ] Machine Translation\n",
    "            - [ ] Question Answering\n",
    "            - [ ] Name-Entity Recognition\n",
    "            - [ ] Word Embeddings\n",
    "            - [ ] Contextual Word Embeddings\n",
    "            - [ ] Coreference Resolution\n",
    "            - [ ] Multitask Learning\n",
    "            - [ ] Constituency Parsing\n",
    "            - [ ] Natural Language Generation\n",
    "            - [ ] Future of NLP\n",
    "        - [ ] Automated Theorem Proving\n",
    "        - [ ] Reinforcement Learning\n",
    "            - [ ] Q-Learning\n",
    "            - [ ] Reinforce\n",
    "            - [ ] Deep Q-Learning\n",
    "            - [ ] Actor Critic Methods\n",
    "            - [ ] Inverse Reinforcement Learning\n",
    "        - [ ] Theoretical Learning Paradigms / Application (Agnostic) Categorizations\n",
    "            - [ ] Supervised Learning\n",
    "            - [ ] Semi-Supervised Learning\n",
    "            - [ ] Unsupervised Learning\n",
    "            - [ ] N-Shot Learning\n",
    "            - [ ] Regression\n",
    "            - [ ] Classification\n",
    "            - [ ] Anomaly Detection\n",
    "            - [ ] Recommender Systems\n",
    "            - [ ] Density Estimation\n",
    "            - [ ] Clustering\n",
    "    - [ ] Illustrative Model Datasets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
